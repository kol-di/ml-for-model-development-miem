{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJn-WZZrt-nP"
      },
      "source": [
        "# Домашнее задание №1: линейная регрессия и векторное дифференцирование.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa-Lia6St-nR"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKQNyiVt-nR"
      },
      "source": [
        "## Многомерная линейная регрессия из sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbVg93IAt-nR"
      },
      "source": [
        "Применим многомерную регрессию из sklearn для стандартного датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCVSClXut-nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3214e8e-8ad5-45b1-bf09-21647a765295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 100) (10000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples = 10000)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m41sLfcJt-nS"
      },
      "source": [
        "У нас 10000 объектов и 100 признаков. Для начала решим задачу аналитически \"из коробки\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx3P6hOVt-nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2546b38e-2cc0-49e6-d015-63155e072119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.026677742145755e-26\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "reg = LinearRegression().fit(X, y)\n",
        "print(mean_squared_error(y, reg.predict(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNWLYeKst-nS"
      },
      "source": [
        "Теперь попробуем обучить линейную регрессию методом градиентного спуска \"из коробки\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK5BO3uxt-nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22e9106-5e10-4ba5-9e85-a7e43a4fedda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7954892143335422e-12\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-7.57684284e-09,  3.76051996e-08,  1.57867155e-08, -1.63266712e-08,\n",
              "       -3.85335165e-08, -3.93034742e-08, -5.12592680e-09,  4.44524954e+01,\n",
              "        4.57962688e+01, -4.06229923e-08,  2.23961465e-08, -5.25854962e-09,\n",
              "       -2.03628420e-08, -2.84074511e-09,  2.12873709e+01,  3.81456351e+01,\n",
              "       -3.42104801e-08,  4.79659404e-09,  5.17606409e-10,  6.30485654e+01,\n",
              "        3.38939474e-08, -2.07275527e-08, -2.77561334e-08,  2.84634435e-08,\n",
              "        5.45884614e+01, -3.16489448e-08,  9.84613777e-09, -3.59313696e-08,\n",
              "        2.16161111e-08, -8.38494814e-10, -2.78212934e-08,  2.53469352e-08,\n",
              "        7.89172412e-09,  3.65233491e+01,  1.35880931e-08,  7.54380909e-09,\n",
              "        1.27886540e-08, -6.20069366e-09,  3.97079248e-08,  2.35231051e-08,\n",
              "       -2.33036492e-08,  3.20720209e-08,  2.82057126e-09, -1.21214625e-08,\n",
              "        1.10698231e-08,  3.40817968e+01, -2.01989464e-10,  1.26384891e-08,\n",
              "       -7.41870436e-09,  2.19058279e-08,  5.97448889e-08, -2.37899084e-08,\n",
              "        1.24314149e-08, -3.89081521e-08,  3.09114175e-08, -5.37773669e-09,\n",
              "       -2.07613077e-08,  8.67139861e-09,  8.54979692e-09, -1.16842264e-08,\n",
              "       -1.02615168e-08,  1.02648422e-08,  3.13713172e-08, -4.40896452e-08,\n",
              "       -2.38205138e-08, -7.16846262e-08,  9.94922024e-10, -1.18428035e-08,\n",
              "        3.88473658e+01,  2.52713337e+01, -8.56858171e-09,  5.75749236e-09,\n",
              "       -1.83087820e-08, -3.66121785e-09, -2.54525686e-08,  1.67083326e-08,\n",
              "       -1.01440219e-08, -2.42580868e-09,  1.10562499e-08,  3.28964764e-08,\n",
              "       -1.35139399e-08,  8.00968170e-09, -2.13454282e-08,  1.30799870e-08,\n",
              "       -6.81730171e-09,  2.61847459e-09, -1.90252916e-08, -1.60450602e-08,\n",
              "        1.28030265e-08, -1.49172443e-08, -3.58779783e-08, -8.78231935e-09,\n",
              "       -3.25231225e-08, -1.44677515e-08, -6.01881569e-08, -1.26732070e-08,\n",
              "       -2.03759183e-08, -6.95774099e-09,  2.20805110e-08,  3.11650937e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "reg = SGDRegressor(alpha=0.00000001).fit(X, y)\n",
        "print(mean_squared_error(y, reg.predict(X)))\n",
        "reg.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MCjcHrSt-nS"
      },
      "source": [
        "***Задание 1 (0.5 балла).*** Объясните, чем вызвано различие двух полученных значений метрики?\n",
        "\n",
        "***Задание 2 (0.5 балла).*** Подберите гиперпараметры в методе градиентного спуска так, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1:** класс LinearRegression использует аналитическую форму для задачи минимизации RSS, соответственно полученная MSE - это минимальное теоретически возможное значение для линейной модели.\n",
        "\n",
        "SGDRegressor также подбирает гиперпараметры линейной модели, но делает это с помощью градиентного спуска вместо решения аналитического уравнения, т.е. ища апроксимацию той самой линейной функции, которая минимизировала бы RSS.\n",
        "\n",
        "Соответственно, качество SGDRegressor никогда не достигнет качества LinearReression, хоть и может очень сильно к нему приблизиться при достаточном количестве итераций."
      ],
      "metadata": {
        "id": "DZk-Xfb-klU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 2**"
      ],
      "metadata": {
        "id": "_uLmZ2e_mWSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "reg = SGDRegressor(alpha=0).fit(X, y)\n",
        "print(mean_squared_error(y, reg.predict(X)))\n",
        "reg.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXhTx8tqmYaS",
        "outputId": "468ec396-32a4-49ad-b00f-960ca08dac02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8745495384831406e-25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.56592928e-15, -1.84542954e-15,  7.92894181e-15,  5.46839897e-15,\n",
              "       -1.08379302e-15, -3.69056948e-15, -1.27370081e-14,  4.44524958e+01,\n",
              "        4.57962693e+01, -1.62081647e-14,  8.86624306e-15, -1.27841791e-14,\n",
              "        4.95619757e-15,  1.91909673e-15,  2.12873712e+01,  3.81456355e+01,\n",
              "       -5.85675485e-15,  2.66170097e-15, -1.02860117e-14,  6.30485661e+01,\n",
              "       -2.92492376e-15, -1.21064128e-14,  2.01710137e-14,  1.29133617e-14,\n",
              "        5.45884619e+01, -6.71141305e-15,  2.15270022e-15, -6.32755225e-15,\n",
              "        3.37327489e-16,  5.60547056e-15, -6.27261069e-15,  2.29069849e-14,\n",
              "       -3.18049390e-15,  3.65233495e+01,  1.35851000e-14,  4.91323277e-15,\n",
              "        3.05625444e-15, -3.59112108e-15,  1.29602866e-14, -1.44293492e-15,\n",
              "        2.58719150e-16,  1.44367292e-14, -5.64632802e-15,  9.91892565e-15,\n",
              "        8.82555781e-15,  3.40817972e+01, -1.47829603e-14,  7.57851628e-15,\n",
              "       -2.01130547e-14,  1.20550321e-14, -5.61636758e-15, -1.25569515e-14,\n",
              "        4.10454746e-15, -1.02880910e-14,  5.08906892e-15, -4.06467177e-15,\n",
              "        3.01743198e-15,  1.43669699e-14,  8.44851927e-15,  2.95907091e-15,\n",
              "        8.31448452e-15,  6.49087451e-15, -5.63497019e-15,  3.00470479e-15,\n",
              "        1.04302528e-14, -1.60270454e-14, -1.07501097e-15,  5.32705853e-15,\n",
              "        3.88473662e+01,  2.52713339e+01,  1.08928062e-14, -5.87428260e-16,\n",
              "       -5.83278693e-15,  4.33608882e-15, -7.49654347e-15, -9.13484347e-15,\n",
              "       -5.90635364e-16,  1.41073794e-14, -5.19794204e-15,  7.05033517e-15,\n",
              "       -1.19672809e-15, -1.00619008e-14,  1.70886342e-14, -8.93199852e-15,\n",
              "        3.08039670e-15,  2.59389176e-15,  6.33604739e-15, -1.28347377e-14,\n",
              "        5.83128789e-15, -9.23162189e-15, -1.64161160e-14, -1.20803885e-14,\n",
              "        7.13306559e-15,  4.59164027e-15, -2.09914876e-14, -1.62511420e-14,\n",
              "        1.49746701e-14, -1.76141389e-15, -2.56889452e-15,  8.80879133e-15])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG7V0qzut-nT"
      },
      "source": [
        "## Ваша многомерная линейная регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJqNQMGHt-nT"
      },
      "source": [
        "***Задание 3 (5 баллов)***. Напишите собственную многомерную линейную регрессию, оптимизирующую MSE методом *градиентного спуска*. Для этого используйте шаблонный класс.\n",
        "\n",
        "Критерий останова: либо норма разности весов на текущей и предыдущей итерациях меньше определенного значения (первый и третий варианты), либо модуль разности функционалов качества (MSE) на текущей и предыдущей итерациях меньше определенного значения (второй и четвертый варианты). Также предлагается завершать обучение в любом случае, если было произведено слишком много итераций.\n",
        "\n",
        "***Задание 4 (2 балла)***. Добавьте l1 регуляризацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TeIxyOot-nT"
      },
      "outputs": [],
      "source": [
        "class LinearRegression(object):\n",
        "    def __init__(self, alpha=0.002, l_ratio=0.00005, tol=0.000001, max_iter=10000, verbose=False):\n",
        "        '''\n",
        "        Для начала необходимо инициализировать параметры\n",
        "        alpha - это learning rate или шаг обучения\n",
        "        l_ratio - параметр регуляризации\n",
        "        tol - значение для критерия останова\n",
        "        max_iter - максимальное количество итераций обучения\n",
        "        '''\n",
        "\n",
        "        self._alpha = alpha\n",
        "        self._l_ratio = l_ratio\n",
        "        self._tol = tol\n",
        "        self._max_iter = max_iter\n",
        "        self._verbose = verbose\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Метод для обучения линейной регрессии\n",
        "        X - матрица признаков\n",
        "        y - вектор правильных ответов\n",
        "        '''\n",
        "\n",
        "        # init all coefficients with zeros\n",
        "        self._weights = np.zeros(X.shape[1])\n",
        "\n",
        "        prev_weights = self._weights\n",
        "        prev_mse = mean_squared_error(y, self.predict(X))\n",
        "        n_iter = 0\n",
        "\n",
        "        while not self._stop_criterion(n_iter, prev_weights, prev_mse, X, y):\n",
        "            prev_weights = self._weights\n",
        "            prev_mse = mean_squared_error(y, self.predict(X))\n",
        "            n_iter += 1\n",
        "\n",
        "            grad = self._grad(X, y)\n",
        "            self._weights = self._weights - self._alpha * grad\n",
        "\n",
        "            if self._verbose:\n",
        "                if not (n_iter % (self._max_iter // 10)):\n",
        "                    print(mean_squared_error(y, self.predict(X)))\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Метод для предсказаний линейной регрессии\n",
        "        X - матрица признаков\n",
        "        '''\n",
        "\n",
        "        return np.dot(X, self._weights)\n",
        "\n",
        "    def _stop_criterion(self, n_iter, prev_weights, prev_mse, X, y):\n",
        "        '''\n",
        "        Возвращает True, если выполнен один из критериев остановки\n",
        "        n_iter - текущая итерация\n",
        "        prev_weights - веса модели на предыдущем шаге\n",
        "        prev_mse - MSE модели на предыдущем шаге\n",
        "        X - матрица признаков\n",
        "        y - таргет\n",
        "        '''\n",
        "        if n_iter == 0:\n",
        "            return False\n",
        "\n",
        "        if n_iter >= self._max_iter:\n",
        "            return True\n",
        "        if np.linalg.norm(prev_weights - self._weights, 1) < self._tol:\n",
        "            return True\n",
        "        if abs(prev_mse - mean_squared_error(y, self.predict(X))) < self._tol:\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _grad(self, X, y):\n",
        "        '''\n",
        "        Рассчитывает градиент для текущих весов\n",
        "        X - матрица признаков\n",
        "        y - таргет\n",
        "        '''\n",
        "\n",
        "        N = len(y)\n",
        "        # closed form solution for partial derivative w.r.t coefficients\n",
        "        grad = (1/N) * np.dot(X.T, np.dot(X, self._weights) - y) + (2 * self._l_ratio * self._weights)\n",
        "        return grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_45PJNw1t-nT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f114b24f-571d-489a-dc41-ff550144ce99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are amazing! Great work!\n"
          ]
        }
      ],
      "source": [
        "my_reg = LinearRegression(alpha=0.002, l_ratio=0.00005, tol=0.000001, max_iter=10000)\n",
        "my_reg.fit(X, y)\n",
        "assert mean_squared_error(y, my_reg.predict(X)) < 1e-3\n",
        "print('You are amazing! Great work!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y, my_reg.predict(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJsu0zEjzgHK",
        "outputId": "8cbd0498-e18d-4332-d2f7-ae25cf773f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.000589798067425905"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-LvqfXkt-nT"
      },
      "source": [
        "***Задание 5 (1 балл)***. Обучите линейную регрессию из коробки\n",
        "\n",
        "* с l1-регуляризацией (from sklearn.linear_model import Lasso)\n",
        "* со значением параметра регуляризации 0.1\n",
        "\n",
        "Обучите вашу линейную регрессию с тем же значением параметра регуляризации и сравните результаты. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXFGXaAwt-nT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4641a160-2ca4-43dc-c370-60153d3df574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10102852663403387\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso = Lasso(alpha=0.1).fit(X, y)\n",
        "print(mean_squared_error(y, lasso.predict(X)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_reg = LinearRegression(alpha=0.0005, l_ratio=0.1, tol=0.000001, max_iter=100000)\n",
        "my_reg.fit(X, y)\n",
        "print(mean_squared_error(y, my_reg.predict(X)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdfmNwrNJMK0",
        "outputId": "1a7df555-b7da-4639-f8d4-5626b052542e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "494.42351261592916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 регуляризация, которая применяется в моей реализации, слишком сильно ограничивает сходимость модели (по сравнению с L1 регуляризацией). Эффект становится тем заметнее, чем выше параметр регуляризации."
      ],
      "metadata": {
        "id": "HWzWoGiyOeSI"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}